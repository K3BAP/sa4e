% !TeX spellcheck = de_DE
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{svg}
\usepackage{float}
\usepackage{caption}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[skip=3pt]{parskip}
\usepackage[ngerman]{babel}
\pagestyle{empty}
\titleformat*{\section}{\large\bfseries}
\titleformat*{\subsection}{\bfseries}

%
\geometry{
	a4paper,
	total={170mm,240mm},
	left=20mm,
	top=30mm,
}

\date{}
%Bitte ausfüllen
\newcommand\course{Software Architectures for Enterprises}
\newcommand\hwnumber{\large Portfolio 3}
\newcommand\Name{Fabian Sponholz}
\newcommand\Neptun{1561546}

%Matheinheiten
\newcommand\m{\:\textrm{m}}
\newcommand\M{\:\Big[\textrm{m}\Big]}
\newcommand\mm{\:\textrm{mm}}
\newcommand\MM{\:\Big[\textrm{mm}\Big]}
\newcommand\un{\underline}
\newcommand\s{\:\textrm{s}}
\newcommand\bS{\:\Big[\textrm{S}\Big]}
\newcommand\ms{\:\frac{\textrm{m}}{\textrm{s}}}
\newcommand\MS{\:\Big[\frac{\textrm{m}}{\textrm{s}}\Big]}
\newcommand\mss{\:\frac{\textrm{m}}{\textrm{s}^2}}
\newcommand\MSS{\:\Big[\frac{\textrm{m}}{\textrm{s}^2}\Big]}

%Trennlinie
\newcommand\separator{\rule{\linewidth}{0.5pt}}

%Bitte nicht einstellen
\renewcommand{\figurename}{Abbildung}
\renewcommand{\tablename}{Tabelle}
\pagestyle{fancyplain}
\headheight 35pt
\lhead{\Name\\\Neptun}
\chead{\textbf{ \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}
	
\section*{Aufgabe 1 - Basis-Architektur}
\subsection*{Erste Überlegungen zur Architektur}
Zuerst habe ich mir überlegt, wie ich das Spiel \emph{Ave Cäsar} auf eine Architektur aus Microservices und einer skalierbaren Datenverwaltung mit Apache Kafka abbilden kann.
Dabei liegt es nahe, in Kafka zunächst für jedes Segment ein eigenes Topic anzulegen, für das dann im Folgenden verschiedene Producer und Consumer erstellt werden können.

Die Streitwagen werden dann jeweils durch eine Message repräsentiert, optimalerweise in Form eines JSON-Strings um Statusinformationen zu transportieren.
 

Jedes Segment wird dann von einem eigenen Microservice repräsentiert, der jeweils als Consumer auf dem ihm zugeordneten Kafka Topic agiert.
So werden ankommende Streitwagen vom Service gefunden und können an das jeweils nächste Segment (bzw. eines der möglichen nächsten Segmente) durch einen Producer weitergeleitet werden, wo bereits der nächste Segment-Service bereitsteht.

Für das Management des Systems muss außerdem ein zentrales Verwaltungsprogramm geschrieben werden, das den Streckenverlauf aus dem zuvor generierten JSON einliest und dann folgende Schritte unternimmt:

\begin{enumerate}
	\item \emph{Setup des Kafka-Servers} - Für jedes Streckensegment und für das Time-Tracking muss ein Kafka-Topic erstellt werden.
	\item \emph{Instantiierung der Microservices} - Für jedes Segment muss eine Instanz des Segment-Service erstellt werden, wobei die nötigen Informationen an das Programm weitergegeben werden müssen.
	\item \emph{Start-and-Goal Segmente} - Mit den Start-And-Goal-Segmenten muss in besonderer Weise kommuniziert werden, damit eine Ausgabe der Gesamtlaufzeit am Ende möglich ist.
	Es ist auch denkbar, die entsprechenden Programme erst bei Start des Rennens zu instantiieren.
	Ein zusätzliches Kafka-Topic sollte verwendet werden, um die Umlaufzeiten zu messen (es ist ja möglich, dass ein Wagen auf einem anderen Segment ankommt als jenes, von dem er gestartet ist).
	\item \emph{Start des Rennens} - Die Start-and-Goal Segmente müssen auf Kommando informiert/instantiiert werden, um die Streitwagen entsprechend ins Rennen zu schicken.
	\item \emph{Ausgabe der Ergebnisse} - Am Ende müssen die Umlaufzeiten der einzelnen Wagen ausgegeben werden.
	\item \emph{Aufräumen} - Die erstellten Prozesse müssen terminiert und die Kafka Topics gelöscht werden.
\end{enumerate}

\subsection*{Implementierung}
Bezüglich der Kafka-Konfiguration habe ich mich an obige Architektur gehalten: Für jedes Segment wird ein Kafka-Topic erstellt und es gibt ein weiteres Kafka-Topic \texttt{timetable}, über das die Start-Goal-Segmente über den Start des Rennens informiert werden und in die die Finish-Zeiten der einzelnen Streitwagen geschrieben werden.

Meine Implementierung besteht aus drei Komponenten: 
\begin{enumerate}
	\item Einer Bibliothek aus Daten-Klassen, die für den Umgang mit JSON-Objekten in der Kurs-Definition und der Messages in den Kafka-Topics zuständig sind.
	\item Einem Micro-Service, der für jedes Segment der Strecke je einmal instantiiert wird und das Weiterleiten an die nächsten Segmente übernimmt.
	\item Ein zentrales Programm, dass die Architektur in Kafka vorbereitet, die Micro-Services startet, das Rennen initiiert und überwacht, das Ergebnis ausgibt und schlussendlich die Micro-Services herunterfährt und die Architektur in Kafka wieder zurücksetzt.
\end{enumerate}

\subsubsection*{Bibliothek aus Daten-Klassen}
Hier habe ich zunächst die Klassen \texttt{CourseDefinition}, \texttt{Track} und \texttt{Segment} erstellt, die zusammen die JSON-Struktur repräsentieren, die von \texttt{circular\_course.py} erstellt wird.
Dazu kommt noch die Klasse \texttt{Chariot}, die einen Streitwagen repräsentiert und als Nachricht in die Kafka-Topics geschrieben wird.
Bisher enthält die Klasse nur eine Streitwagen-ID und einen Rundenzähler, wird aber vermutlich in Aufgabe 3 noch erweitert werden.
Zuletzt gibt es noch eine Klasse \texttt{TimetableEntry}, die die Nachrichten im \texttt{timetable}-Topic repräsentieren.
Wo es erforderlich ist enthalten die Klassen je eine Methode \texttt{toJson()} und eine statische Methode \texttt{fromJson()}, die mithilfe von \emph{Gson} die entsprechenden Konversionen von und nach JSON realisieren.

\subsubsection*{Segment-Service}
Diese Komponente enthält das Interface \texttt{SegmentRoutine}, durch welches verschiedene Verhaltensweisen für die verschiedenen Segment-Typen erzielt werden.
Für Aufgabe 1 stehen folgende Implementierungen zur Verfügung:
\begin{itemize}
	\item \texttt{StandardSegment} repräsentiert das Segment vom Typ \texttt{normal}.
	Hier werden in der Hauptroutine mit einem Consumer die Streitwagen vom dem Segment zugeordneten Topic abgerufen und dann einfach zufällig an eines der nachfolgenden Segmente weitergegeben, indem sie per Producer in das entsprechende Topic geschrieben werden.
	
	\item \texttt{StartAndGoal} repräsentiert das Segment vom Typ \texttt{start-goal}.
	Es verhält sich weitestgehend wie das \texttt{StandardSegment} und erbt auch von diesem.
	Es wurden allerdings ein paar zusätzliche Features eingebaut:
	\begin{itemize}
		\item Neben seinem eigenen Topic lauscht das Segment auch auf dem Topic \texttt{timetable}.
		Wird dort eine Nachricht gesendet, die den Start des Rennens markiert, wird ein neuer Streitwagen erstellt und auf eines der nachfolgenden Segmente befördert.
		
		\item Wenn ein Streitwagen das Segment passiert, wird der Rundenzähler um eins erhöht
		
		\item Hat der Streitwagen alle Runden absolviert, so wird er nicht weitergeleitet und stattdessen ein Eintrag in das Topic \texttt{timetable} geschrieben.
		Dieser Eintrag enthält die Systemzeit zum Zeitpunkt des Eintreffens, um eine Laufzeitmessung für die ganze Strecke zu realisieren.
	\end{itemize}
\end{itemize}
Die \texttt{Main}-Klasse des Programms bekommt eine JSON-Repräsentation des Segments, für dass die Instanz verantwortlich ist, als Argument übergeben.
Nachfolgend wird anhand des \texttt{type}-Attributs entschieden, welche Implementierung für die \texttt{SegmentRoutine} verwendet wird, und diese wird initialisiert und gestartet.

\subsubsection*{Admin-Tool}
Das Admin-Tool bekommt als Argument einen Pfad zu einer JSON-Datei übergeben, in der sich die Kurs-Definition befindet.
Diese wird aus dem JSON eingelesen und steht fortan als Objekt in Java zur Verfügung.

Dann werden über einen Kafka \texttt{AdminClient} alle notwendigen Topics erstellt: Je eines für jedes Segment und ein weiteres Topic \texttt{timetable} für die Zeiterfassung und Steuerung.

Als nächstes werden die Service-Prozesse gestartet und in einer Liste verwaltet, um diese später wieder beenden zu können.

Nachdem alle Prozesse erstellt wurden, kann das Rennen durch einen Druck der Enter-Taste gestartet werden.
Dies geschieht, indem ein \texttt{TimetableEntry}-Objekt mit Typ \texttt{started} in das \texttt{timetable}-Topic geschrieben wird.

Nun wird außerdem ein Observer-Thread gestartet, der das \texttt{timetable}-Topic beobachtet und eine Meldung ausgibt, sobald ein Streitwagen (bzw. alle Streitwagen) im Ziel ist.

Nach einem weiteren Druck auf die Enter-Taste wird der Thread beendet, falls nicht schon geschehen, die Service-Prozesse terminiert und die Kafka-Topics wieder gelöscht.

\subsection*{Zeitmessung}
Für den finalen Test habe ich einen Kurs mit zwei Spuren und je 10 Segmenten erstellt. 
Für diesen Kurs brauchten die Streitwagen jeweils etwa 500ms, wenn man vor Rennstart ein paar Sekunden wartet, bis Kafka das Erstellen der Topics vollständig verarbeitet hat. 
Wartet man nicht, so dauert es auch schon mal 7000ms.

\subsection*{Probleme bei der Implementierung}
Ich bin bei der Implementierung auf einige Hürden gestoßen, von denen ich hier ein paar nennen möchte.

\begin{itemize}
	\item Zunächst wurden die Einträge zeitversetzt in die Topics geschrieben, wodurch die Geschwindigkeit der Streitwagen erheblich litt. 
	Hier war einige zusätzliche Konfiguration der Producer (insbesondere das Setzen des Parameters \texttt{linger.ms} auf \texttt{0}) notwendig, um die Latenzen in den Griff zu bekommen.
	
	\item Die Consumer waren zunächst auch nicht ganz korrekt konfiguriert, sodass sie nur die Nachrichten erhielten, die NACH ihrer Instantiierung geschrieben worden waren.
	Insbesondere beim Observer im Admin-Tool führte das regelmäßig dazu, dass der Zieleinlauf der Streitwagen "verpasst" wurde.
	Auch hier konnte ich das Problem durch ein paar Konfigurations-Optionen lösen.
	
	\item Das Jonglieren mit Prozessen in Java ist immer etwas lästig, vor allem wenn die Prozesse nicht korrekt beendet werden.
	Es brauchte etwas Aufwand, bis ich eine relativ robuste Lösung gefunden habe, die eine Beendigung der Prozesse zu jeder Zeit möglich macht und mich nicht zu regelmäßigen Aufräummaßnahmen (\texttt{killall -9 java}) zwingt. (Lösung: Observer in separatem Thread statt im Main-Thread, sodass der Main-Thread weiter auf Eingaben lauschen kann.)
	Außerdem habe ich zuerst das Ausmaß der Beispielstrecke viel zu groß gewählt, sodass mein Rechner beim Starten der vielen Prozesse eingefroren ist und ich einen Hard-Reset machen musste.
	Wenn die Services aber auf vielen Rechnern verteilt laufen würden, wäre das kein Problem.
	Theoretisch wären mit Kafka sogar mehrere Instanzen des selben Service möglich, auf die die eingehenden Messages verteilt werden.
\end{itemize}

\section{Aufgabe 2 - Cluster}
Ab Version 4.0 enthält Apache Kafka ein eigenes Framework für die Cluster-Koordination.
Mithilfe einer Docker-Compose-Datei habe ich drei Instanzen von Kafka erstellt und untereinander koordiniert.
Um das Potenzial voll auszuschöpfen, kann jetzt noch der Replikations- bzw. Partitions-Faktor der Topics erhöht werden.

\end{document}